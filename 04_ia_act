# L'AI Act : Comprendre la nouvelle réglementation européenne sur l'intelligence artificielle

## Introduction

L'AI Act est la première législation complète au monde dédiée à la régulation de l'intelligence artificielle (IA). Proposée par l'Union européenne, elle vise à encadrer le développement, l'utilisation et la commercialisation des systèmes d'IA pour garantir la sécurité, la transparence et le respect des droits fondamentaux.

---

## Objectifs principaux de l'AI Act

1. **Protéger les citoyens européens** face aux risques liés aux technologies d'IA.
2. **Encourager l'innovation** en offrant un cadre juridique stable.
3. **Assurer la transparence** et la traçabilité des systèmes d'IA.
4. **Établir un cadre commun** pour tous les États membres afin d'éviter la fragmentation juridique.

---

## Approche basée sur les risques

L'AI Act classe les systèmes d'IA en plusieurs catégories de risque. Chaque niveau implique des obligations spécifiques.

### 1. IA à risque inacceptable

Ces systèmes sont **interdits**, car ils présentent une menace pour les droits fondamentaux.

Exemples :

* Manipulation cognitive ciblée (par ex. jouets incitant un enfant à un comportement dangereux)
* Systèmes de notation sociale par les gouvernements
* Reconnaissance émotionnelle sur le lieu de travail

### 2. IA à haut risque

Ces systèmes sont **strictement réglementés**.

Sont concernés :

* Les infrastructures critiques, comme les transports
* La santé (diagnostic, dispositifs médicaux)
* L'éducation (notation automatisée)
* Le recrutement ou la gestion du personnel
* Les systèmes biométriques (sauf cas d'interdiction)

Obligations pour les développeurs :

* Gestion du risque documentée
* Qualité des données d'entraînement
* Transparence et traçabilité du modèle
* Supervision humaine
* Sécurité et robustesse

### 3. IA à risque limité

Ces systèmes doivent respecter certaines obligations de **transparence**.

Exemples :

* Chatbots
* Deepfakes

Le public doit être informé qu'il interagit avec une IA.

### 4. IA à risque minimal

Ces systèmes sont **librement autorisés**.

Exemples :

* Jeux vidéo utilisant l'IA
* Filtres photo
* Recommandations de contenu non sensibles

---

## Les obligations pour les acteurs de l'IA

### Fournisseurs (développeurs)

* Documentation technique complète
* Analyse des risques
* Processus de qualité pour les données
* Tests réguliers de sécurité
* Enregistrement des systèmes à haut risque

### Déployeurs (utilisateurs institutionnels ou professionnels)

* Surveillance humaine
* Utilisation conforme à la documentation
* Signalement des incidents graves

---

## Régulation des modèles d'IA générative

L'AI Act introduit des exigences spécifiques pour les modèles d'IA générative (comme GPT ou les modèles de génération d'images).

Obligations :

* Indiquer que les contenus générés sont artificiels
* Documenter l'utilisation de droits d'auteur dans les données d'entraînement
* Mettre en place des protections contre les abus (désinformation, contenu illégal)

Les modèles dits *fondationnels* (Foundation Models) sont soumis à des règles encore plus strictes concernant la sécurité, la robustesse et la transparence.

---

## Sanctions

Les entreprises qui ne respectent pas l'AI Act s'exposent à des amendes importantes :

* Jusqu'à **35 millions d'euros** ou **7 % du chiffre d'affaires mondial** pour les violations les plus graves.
* Jusqu'à 15 millions d'euros ou 3 % du CA pour d'autres manquements.

---

## Mise en application

L'AI Act sera déployé progressivement :

* Interdictions : quelques mois après l'adoption
* Règles pour les modèles fondationnels : environ un an après
* IA à haut risque : jusqu'à deux ans avant pleine application

---

## Conclusion

L'AI Act marque une étape décisive dans la gouvernance mondiale de l'intelligence artificielle. Grâce à son approche équilibrée, il vise à protéger les citoyens tout en soutenant l'innovation. Sa compréhension est essentielle pour les développeurs, organisations et utilisateurs souhaitant travailler avec l'IA en Europe.

---